{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Ethnicity Classification for Customer Names\n",
    "\n",
    "## Problem Statement\n",
    "In the realm of e-commerce and customer analytics, understanding the diverse demographics of a business customer base is crucial. This project aims to predict the ethnicity of customers based on their names using machine learning techniques. The challenge lies in developing accurate models that can infer ethnicity from names, considering the multicultural diversity within the customer database.\n",
    "\n",
    "## Objective\n",
    "The primary objective of this project is to build and evaluate machine learning models, including Naive Bayes, Random Forest, and SVM, to predict the likely ethnicity of customers based on their names. By leveraging natural language processing and classification algorithms, the project seeks to provide insights into the ethnic distribution of customers within the dataset. This predictive capability can enhance demographic profiling and enable more targeted marketing strategies tailored to specific ethnic groups.\n",
    "\n",
    "## Approach\n",
    "1. Preprocess the textual data by tokenization, stemming, and removing stopwords.\n",
    "2. Vectorize the processed names using techniques like CountVectorizer to convert text into numerical features.\n",
    "3. Train and evaluate machine learning models, including Naive Bayes, Random Forest, and SVM.\n",
    "4. Predict the ethnicity of new customer names using the trained models.\n",
    "5. Analyze and compare the performance of different models.\n",
    "\n",
    "## Expected Outcome\n",
    "The project aims to deliver accurate ethnicity predictions for customer names, facilitating a deeper understanding of the customer demographics. This predictive capability can inform business decisions, marketing strategies, and personalized customer engagement efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "#file with race data\n",
    "data = pd.read_excel(r\"data\\jan23-jun23_ethnic.xlsx\")\n",
    "#data = data.sample(frac=0.04, random_state=42) smaller dataset used during code testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert full_name column from integers to string\n",
    "data['ShippingName'] = data['ShippingName'].astype(str)\n",
    "\n",
    "#remove rows where Ethnicity has False values\n",
    "data = data[data['Ethnicity'] != False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [stemmer.stem(word) for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data['processed_name'] = data['ShippingName'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['processed_name'], data['Ethnicity'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline accuracy (predicting the most frequent class)\n",
    "baseline_accuracy = y_test.value_counts().max() / len(y_test)\n",
    "print(f'Baseline Accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag: customer_names_handling\n",
    "# Feature extraction using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Notes about feature extraction from customer names\n",
    "#TikTok MY customers have a shipping_firsname which is encapsulated within asterisks (TikTok's pirvacy policy), therefore the model has ignores those names when tokenizing the names\n",
    "#For Jul 23 - Sep 23 dataset, they represent around 500 observations out of the 40k+ observations, so the effect of considering those names as \"Others\" is insignificant as it represents less than 1% of the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "# Dispay test dataset with actual vs predicted values\n",
    "\n",
    "# Create a DataFrame with the test dataset and a copy of relevant columns\n",
    "results_table_nb = pd.DataFrame({'Processed Name': X_test, 'Actual Ethnicity': y_test, 'Predicted Ethnicity': predictions})\n",
    "\n",
    "# Display the table\n",
    "print('\\nActual vs Predicted Ethnicity Table (Naive Bayes Classifier):')\n",
    "print('Test Dataset (Random 20% of values)')\n",
    "print(results_table_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set using Random Forest\n",
    "rf_predictions = rf_classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print('\\nClassification Report (Random Forest):')\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf_classifier.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances_rf = [(feature, round(importance, 2)) for feature, importance in zip(vectorizer.get_feature_names_out(), importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances_rf = sorted(feature_importances_rf, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Show top 10 feature importances\n",
    "top_feature_importances_rf = feature_importances_rf[:10]\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in top_feature_importances_rf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importances\n",
    "features, importances = zip(*top_feature_importances_rf)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(features, importances, color='skyblue')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "# Dispay test dataset with actual vs predicted values\n",
    "\n",
    "# Create a DataFrame with the test dataset and a copy of relevant columns\n",
    "results_table_rf = pd.DataFrame({'Processed Name': X_test, 'Actual Ethnicity': y_test, 'Predicted Ethnicity': rf_predictions})\n",
    "\n",
    "# Display the table\n",
    "print('\\nActual vs Predicted Ethnicity Table (Random Forest):')\n",
    "print('Test Dataset (Random 20% of values)')\n",
    "print(results_table_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train a Support Vector Machine (SVM) classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "svm_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test set using SVM\n",
    "svm_predictions = svm_classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')\n",
    "print('\\nClassification Report (SVM):')\n",
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Dispay test dataset with actual vs predicted values\n",
    "\n",
    "# Create a DataFrame with the test dataset and a copy of relevant columns\n",
    "results_table_svm = pd.DataFrame({'Processed Name': X_test, 'Actual Ethnicity': y_test, 'Predicted Ethnicity': svm_predictions})\n",
    "\n",
    "# Display the table\n",
    "print('\\nActual vs Predicted Ethnicity Table (SVM):')\n",
    "print('Test Dataset (Random 20% of values)')\n",
    "print(results_table_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with model accuracies\n",
    "accuracy_df = pd.DataFrame({\n",
    "    'Model': ['Naive Bayes', 'Random Forest', 'SVM'],\n",
    "    'Accuracy': [accuracy, rf_accuracy, svm_accuracy]\n",
    "})\n",
    "\n",
    "# Display the accuracy table\n",
    "print('\\nModel Accuracies:')\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Detailed model performance metrics\n",
    "# Function to create a pretty table from a classification report\n",
    "def create_pretty_table(report, model_name):\n",
    "    table = PrettyTable()\n",
    "    \n",
    "    # Check if the report is a dictionary\n",
    "    if isinstance(report, dict):\n",
    "        table.field_names = [\"Class\"] + list(report['weighted avg'].keys())\n",
    "        for cls, values in report.items():\n",
    "            # Check if values is a dictionary\n",
    "            if isinstance(values, dict):\n",
    "                table.add_row([cls] + list(values.values()))\n",
    "    else:\n",
    "        # Handle case where the report is a single float value\n",
    "        table.field_names = [\"Metric\", \"Value\"]\n",
    "        table.add_row([\"Accuracy\", report])\n",
    "\n",
    "    table.title = f\"Classification Report ({model_name})\"\n",
    "    return table\n",
    "\n",
    "# Create classification reports\n",
    "report_nb = classification_report(y_test, predictions, output_dict=True)\n",
    "report_rf = classification_report(y_test, rf_predictions, output_dict=True)\n",
    "report_svm = classification_report(y_test, svm_predictions, output_dict=True)\n",
    "\n",
    "# Create PrettyTables for each classification report\n",
    "table_nb = create_pretty_table(report_nb, \"Naive Bayes\")\n",
    "table_rf = create_pretty_table(report_rf, \"Random Forest\")\n",
    "table_svm = create_pretty_table(report_svm, \"SVM\")\n",
    "\n",
    "# Print individual tables\n",
    "print(table_nb)\n",
    "print(table_rf)\n",
    "print(table_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for all three models\n",
    "# model performance assessment on test data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Function to create confusion matrix and plot it\n",
    "def plot_confusion_matrix(ax, y_true, y_pred, model_name, color):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=data['Ethnicity'].unique())\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=color, xticklabels=data['Ethnicity'].unique(), yticklabels=data['Ethnicity'].unique(), ax=ax)\n",
    "    ax.set_title(f'Confusion Matrix - {model_name}')\n",
    "    ax.set_xlabel('Predicted Ethnicity')\n",
    "    ax.set_ylabel('Actual Ethnicity')\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Confusion matrix and plot for Naive Bayes\n",
    "plot_confusion_matrix(axes[0], y_test, predictions, 'Naive Bayes', 'Blues')\n",
    "\n",
    "# Confusion matrix and plot for Random Forest\n",
    "plot_confusion_matrix(axes[1], y_test, rf_predictions, 'Random Forest', 'Greens')\n",
    "\n",
    "# Confusion matrix and plot for SVM\n",
    "plot_confusion_matrix(axes[2], y_test, svm_predictions, 'SVM', 'Reds')\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification ROC Curves\n",
    "# Import necessary libraries for ROC curves\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Function to plot ROC curves for each category and each model\n",
    "def plot_roc_curves(model, model_name, predictions, y_test):\n",
    "    \n",
    "    # Get the unique categories\n",
    "    categories = data['Ethnicity'].unique()\n",
    "    \n",
    "    for category in categories:\n",
    "        # Create binary ground truth for the specific category\n",
    "        y_true_category = (y_test == category)\n",
    "        # Create binary predictions for the specific category\n",
    "        y_pred_category = (predictions == category)\n",
    "        \n",
    "        # Compute ROC curve for the specific category\n",
    "        fpr, tpr, _ = roc_curve(y_true_category, y_pred_category)\n",
    "        # Compute AUC for the specific category\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve for the specific category\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve for {category} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Chance level (AUC = 0.5)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curves - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curves for Naive Bayes\n",
    "plot_roc_curves(classifier, 'Naive Bayes', predictions, y_test)\n",
    "\n",
    "# Plot ROC curves for Random Forest\n",
    "plot_roc_curves(rf_classifier, 'Random Forest', rf_predictions, y_test)\n",
    "\n",
    "# Plot ROC curves for SVM\n",
    "plot_roc_curves(svm_classifier, 'SVM', svm_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One vs Rest Classifier ROC\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert labels to numerical values for ROC curve\n",
    "y_test_bin = label_binarize(y_test, classes=data['Ethnicity'].unique())\n",
    "\n",
    "def plot_multiclass_roc(model, model_name):\n",
    "    # One-vs-Rest strategy\n",
    "    classifier = OneVsRestClassifier(model)\n",
    "    classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "    # Access model's predictions (or decision function for SVC)\n",
    "    if isinstance(classifier, OneVsRestClassifier) and isinstance(classifier.estimators_[0], SVC):\n",
    "        y_score = classifier.decision_function(X_test_vectorized)\n",
    "    else:\n",
    "        y_score = classifier.predict_proba(X_test_vectorized)\n",
    "\n",
    "    # Initialize variables to store fpr, tpr, and roc_auc for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    for i in range(y_test_bin.shape[1]):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Plot ROC curve for each class\n",
    "        plt.plot(fpr[i], tpr[i], label=f'ROC curve for {data[\"Ethnicity\"].unique()[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Multiclass ROC curves - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curves for each model\n",
    "plot_multiclass_roc(MultinomialNB(), 'Naive Bayes')\n",
    "plot_multiclass_roc(RandomForestClassifier(random_state=42), 'Random Forest')\n",
    "plot_multiclass_roc(SVC(random_state=42, probability=True), 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the models to predict on new data\n",
    "# Upload new data file\n",
    "new_data = pd.read_excel('data/HJecommQ3blankethnicity.xlsx')\n",
    "new_data['shipping_firstname'] = new_data['shipping_firstname'].astype(str)\n",
    "new_data['processed_name'] = new_data['shipping_firstname'].apply(preprocess_text)\n",
    "\n",
    "# Vectorize the new data\n",
    "new_data_vectorized = vectorizer.transform(new_data['processed_name'])\n",
    "\n",
    "# Predictions using Naive Bayes\n",
    "new_predictions_nb = classifier.predict(new_data_vectorized)\n",
    "\n",
    "# Predictions using Random Forest\n",
    "new_predictions_rf = rf_classifier.predict(new_data_vectorized)\n",
    "\n",
    "# Predictions using SVM\n",
    "new_predictions_svm = svm_classifier.predict(new_data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "link_html = '<a href=\"#customer_names_handling\">Refer to special name nomenclature cases</a>'\n",
    "display(HTML(link_html))\n",
    "\n",
    "# Handling special cases of customer names\n",
    "# Define exceptional cases\n",
    "exceptional_cases = [\"nan\", \"\"]\n",
    "\n",
    "# Assign \"Others\" to predicted ethnicity for rows where processed_name matches exceptional cases\n",
    "for case in exceptional_cases:\n",
    "    new_predictions_nb[new_data['processed_name'] == case] = 'Others'\n",
    "    new_predictions_rf[new_data['processed_name'] == case] = 'Others'\n",
    "    new_predictions_svm[new_data['processed_name'] == case] = 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions to the new dataset\n",
    "new_data['Predicted_Ethnicity_NB'] = new_predictions_nb\n",
    "new_data['Predicted_Ethnicity_RF'] = new_predictions_rf\n",
    "new_data['Predicted_Ethnicity_SVM'] = new_predictions_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data and time for file nomenclature\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current date and time\n",
    "current_datetime = datetime.now().strftime(\"%d%m%Y_%H%M%S%p\")\n",
    "print(current_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export file\n",
    "new_data.to_excel(f'Data/Predictions/ecomm_demo_2023Q3_predicted_ethnicities_{current_datetime}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
